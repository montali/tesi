\chapter{Stato dell'arte}
\label{chap:stateofart}
Illustriamo ora lo stato dell'arte delle varie tecniche e tecnologie che coinvolgono il bot.
\section{Machine Learning}
Il machine learning è una disciplina che si occupa di rispondere, sostanzialmente, a due domande: \textit{Come si può costruire un sistema informatico che migliora con l'esperienza?} e \textit{Quali sono le leggi teoriche fondamentali che governano ogni sistema di apprendimento, sia esso implementato nei computer, negli umani, nelle organizzazioni?}. Il machine learning copre una serie di compiti diversi, dalla classificazione di email spam, al riconoscimento facciale, al controllo di robot \cite{book:mitchell1997machine}. Ogni problema di machine learning può essere riassunto come il miglioramento di una determinata performance (data, ad esempio, dall'errore sulle predizioni) durante l'esecuzione di un'operazione. Seguendo l'esempio delle email spam, un algoritmo di machine learning potrebbe apprendere, tramite un \textit{training set} di email già etichettate come spam/non-spam, a categorizzarne altre.
Portando il problema in termini matematici, vogliamo, dato un grafico
% TODO: crea grafico con punti rossi/blu per spammy/non-spammy
in cui i punti rossi sono email spam, e quelli blu no, trovare una funzione che ci permetta di evidenziare le email da eliminare. Ciò che faremo sarà quindi definire un insieme di \textbf{features}, consistenti, ad esempio, nel contenuto testuale della mail (vettorizzato in termini numerici), l'orario di arrivo, la lunghezza in parole\dots Oltre a ciò, definiremo una \textbf{label}, ossia la caratteristica che vogliamo predirre: sarà, per esempio, 1 se l'email è spam, 0 altrimenti. Ora, il problema consiste in una semplice regressione lineare: date le features $x_0, x_1, x_2$ e la label $y$, vogliamo trovare dei pesi $w_0, w_1, w_2$ tali che
\begin{displaymath}
    w_0x_0+w_1x_1+w_2x_2
\end{displaymath}
approssimi al meglio $y$. Per fare ciò, procediamo per iterazioni: partiremo con dei pesi arbitrari, calcolando $y$ per ogni esempio (già etichettato) fornito, e ne calcoleremo l'errore rispetto alla $y$ reale. Potremo quindi calcolare il gradiente (ossia la somma delle derivate parziali sui rispettivi pesi) della funzione che lega l'errore ai pesi $w_i$, ottenendone un'informazione fondamentale: indicherà infatti la direzione nella quale la funzione errore è decrescente. Ci potremo quindi spostare, di una quantità pari al \textit{learning rate} (uno degli iperparametri definiti arbitrariamente), nella direzione di diminuzione dell'errore. Scegliere un corretto \textit{learning rate} è una parte fondamentale dello sviluppo dell'algoritmo di machine learning: se è troppo piccolo, la soluzione richiederà troppo tempo, se troppo grande, la soluzione non sarà abbastanza precisa. Dopo un sufficiente numero di esecuzioni dell'algoritmo, il nostro grafico avrà ora questo aspetto:
% TODO: Grafico categorizzato
e saremo quindi in grado di determinare, con una determinata \textit{accuracy}, l'appartenenza di un esempio ad una classe o all'altra.